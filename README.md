# ğŸ” Phase 3: Monitoring & Drift Detection

<div align="center">

![Status](https://img.shields.io/badge/Status-Observation--Only-blue?style=for-the-badge)
![Phase](https://img.shields.io/badge/Phase-3%2F6-orange?style=for-the-badge)
![MLOps](https://img.shields.io/badge/MLOps-Production--Grade-success?style=for-the-badge)

**Passive monitoring layer with statistical drift detection**

[Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Configuration](#-configuration) â€¢ [Troubleshooting](#-troubleshooting)

</div>

---

## ğŸ“‹ Table of Contents

- [What's New](#-whats-new-in-phase-3)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Key Concepts](#-key-concepts)
- [Configuration](#-configuration)
- [Verification](#-verification)
- [Troubleshooting](#-troubleshooting)

---

## âœ¨ What's New in Phase 3

<table>
<tr>
<td width="50%">

### ğŸ¯ Core Components

| Component | Purpose |
|-----------|---------|
| ğŸ“¦ **Frozen Reference** | Immutable baseline for comparison |
| ğŸ“ **Prediction Logger** | Append-only storage |
| ğŸ“Š **Proxy Metrics** | Label-free trend analysis |
| ğŸ”¬ **Drift Detection** | Statistical tests via Evidently |
| âš™ï¸ **Monitoring Job** | Batch analytics processor |
| â° **Scheduler** | Simple orchestration |

</td>
<td width="50%">

### ğŸš« What Phase 3 Does NOT Do

- âŒ Trigger retraining
- âŒ Update models
- âŒ Send alerts
- âŒ Compute accuracy
- âŒ Make decisions

<br/>

> **Phase 3 = Observation**  
> **Phase 4 = Action**

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    A[User Request] -->|POST /predict| B[API Service]
    B --> C[Model Prediction]
    C --> D[Log to CSV]
    D --> E[Prediction Storage]
    
    F[Scheduler] -->|Every 5 min| G[Monitoring Job]
    G --> E
    G --> H{Check Sample Count}
    H -->|< 200| I[Skip Analysis]
    H -->|â‰¥ 200| J[Run Analytics]
    
    J --> K[Proxy Metrics]
    J --> L[Drift Detection]
    
    K --> M[JSON Results]
    L --> M
    M --> N[MLflow Logging]
    M --> O[HTML Reports]
    
    style B fill:#4CAF50
    style G fill:#2196F3
    style J fill:#FF9800
    style I fill:#f44336
```

### ğŸ”„ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Requestâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API: Prediction + Logging          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  predictions.csv (append-only)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
   [5 minutes]
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitoring Job Wake Up             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sample Check (â‰¥200?)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Proxy Metricsâ”‚  Drift Detection     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Results: JSON + HTML + MLflow       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

<table>
<tr>
<td>

**âœ… Required**
- Phase 2 completed
- Docker Compose
- Training data ready

</td>
<td>

**ğŸ“Š Status Check**
```bash
docker --version
docker-compose --version
ls data/cs-training.csv
```

</td>
</tr>
</table>

### ğŸ”§ Setup Steps

<details open>
<summary><b>Step 1: Clean Start (Optional)</b></summary>

```bash
# Remove old data
docker-compose down -v
rm -rf mlflow/ monitoring/

# Create fresh directories
mkdir -p monitoring/{predictions,reference,metrics,reports}
```

</details>

<details open>
<summary><b>Step 2: Initialize Infrastructure</b></summary>

```bash
# Start MLflow
docker-compose up -d mlflow
sleep 10

# Bootstrap reference data (âš ï¸ ONE-TIME operation)
docker-compose run --rm bootstrap
```

**Expected Output:**
```
âœ… Saved reference data: /app/monitoring/reference/reference_data.csv
âœ… Saved metadata: /app/monitoring/reference/reference_metadata.json
```

</details>

<details open>
<summary><b>Step 3: Train & Deploy Model</b></summary>

```bash
# Train model
docker-compose up trainer

# Verify in MLflow UI
open http://localhost:5000
```

ğŸ“ **Manual Step**: Promote model to Production in MLflow UI  
`Models â†’ credit-risk-model â†’ Version X â†’ Transition to Production`

</details>

<details open>
<summary><b>Step 4: Start Services</b></summary>

```bash
# Start API + Monitoring
docker-compose up -d api monitoring

# Verify all services running
docker-compose ps
```

**Expected:**
```
NAME                    STATUS
mlflow-server          Up (healthy)
credit-risk-api        Up (healthy)
monitoring-scheduler   Up
```

</details>

<details open>
<summary><b>Step 5: Generate Test Data</b></summary>

```bash
# Generate 250 predictions (need 200+ for analysis)
for i in {1..250}; do
  curl -s -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{
      "RevolvingUtilizationOfUnsecuredLines": 0.766127,
      "age": 45,
      "NumberOfTime30_59DaysPastDueNotWorse": 2,
      "DebtRatio": 0.802982,
      "MonthlyIncome": 9120.0,
      "NumberOfOpenCreditLinesAndLoans": 13,
      "NumberOfTimes90DaysLate": 0,
      "NumberRealEstateLoansOrLines": 6,
      "NumberOfTime60_89DaysPastDueNotWorse": 0,
      "NumberOfDependents": 2
    }' > /dev/null
  echo -ne "Progress: $i/250\r"
done
echo -e "\nâœ… Generated 250 predictions"
```

</details>

<details open>
<summary><b>Step 6: View Results</b></summary>

```bash
# Wait 5 minutes OR force immediate run
docker-compose exec monitoring python src/monitoring/monitoring_job.py

# Check results
ls monitoring/metrics/monitoring_results/
ls monitoring/reports/drift_reports/

# Pretty-print latest result
ls -t monitoring/metrics/monitoring_results/*.json | head -1 | xargs cat | jq '.'
```

</details>

---

## ğŸ“‚ Project Structure

```
self-healing-mlops/
â”‚
â”œâ”€â”€ ğŸŒ src/
â”‚   â”œâ”€â”€ api_mlflow.py                    # Prediction API
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ’¾ storage/
â”‚   â”‚   â””â”€â”€ prediction_logger.py         # Append-only logging
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š analytics/
â”‚   â”‚   â”œâ”€â”€ proxy_metrics.py             # Trend analysis
â”‚   â”‚   â””â”€â”€ drift_detection.py           # Evidently wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” monitoring/
â”‚   â”‚   â””â”€â”€ monitoring_job.py            # Batch processor
â”‚   â”‚
â”‚   â””â”€â”€ â° orchestration/
â”‚       â””â”€â”€ scheduler.py                 # Job scheduler
â”‚
â”œâ”€â”€ ğŸ”§ scripts/
â”‚   â””â”€â”€ bootstrap_reference.py           # Reference data creator
â”‚
â”œâ”€â”€ ğŸ“ monitoring/
â”‚   â”œâ”€â”€ ğŸ“¦ reference/                    # IMMUTABLE
â”‚   â”‚   â”œâ”€â”€ reference_data.csv
â”‚   â”‚   â””â”€â”€ reference_metadata.json
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ predictions/                  # Append-only
â”‚   â”‚   â””â”€â”€ predictions.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ˆ metrics/                      # Analysis results
â”‚   â”‚   â””â”€â”€ monitoring_results/
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ reports/                      # Evidently HTML
â”‚       â””â”€â”€ drift_reports/
â”‚
â””â”€â”€ ğŸ³ docker-compose.yml
```

---


## ğŸ¯ Success Criteria

<div align="center">

### Phase 3 Complete When:

</div>

<table>
<tr>
<td>

- [x] ğŸ“¦ Reference data created & verified
- [x] ğŸ¯ Model in Production stage
- [x] ğŸ“ API logs predictions to CSV
- [x] ğŸ’¯ 200+ predictions accumulated
- [x] âš™ï¸ Monitoring job runs without errors

</td>
<td>

- [x] ğŸ“Š Results appear in `metrics/`
- [x] ğŸ“„ Drift reports in `reports/`
- [x] â„¹ï¸ INFO-level logs (no warnings)
- [x] ğŸ”’ Reference integrity verified
- [x] ğŸŒ All services healthy

</td>
</tr>
</table>

---

## ğŸ”œ What's Next?

<div align="center">

### Phase 4: Automated Retraining Pipeline

**Coming Soon:**
- ğŸ·ï¸ Delayed label handling
- ğŸ­ Shadow model training
- âœ… Evaluation gates (retrain decision logic)
- ğŸš€ Automated model promotion
- ğŸ”„ Self-healing loop completion

</div>

---

<div align="center">

### ğŸ—ï¸ Phase 3 Complete!

**You've built a production-grade monitoring foundation.**

Phase 3 establishes **observability infrastructure**.  
Phase 4 adds **automated decision-making**.

---

**Built with discipline** â€¢ **Deployed with confidence** â€¢ **Monitored with precision**

[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-â¤ï¸-red?style=for-the-badge)](https://github.com/yourusername)

</div>

# Self-Healing MLOps Pipeline

## Phase 1 â€” Foundation: Prediction Service

This repository contains **Phase 1** of a multi-phase **Self-Healing MLOps Pipeline**.

The objective of this phase is **not** to build a self-healing system yet.
Instead, Phase 1 focuses on creating a **correct, reproducible, and observable ML prediction system** that later phases can safely extend with monitoring, drift diagnosis, and controlled retraining.

---

## ğŸ¯ Phase 1 Objectives

Phase 1 is intentionally limited in scope. Its purpose is to establish engineering discipline and system correctness.

This phase ensures:

* Deterministic data loading
* Frozen preprocessing shared between training and inference
* Explicit feature schema preservation
* Versioned model artifacts
* FastAPI-based prediction service
* Input validation with Pydantic
* Time-stamped prediction logging
* Reproducible execution

---

## ğŸš« What This Phase Does *Not* Do

The following are **explicitly out of scope** for Phase 1:

* No drift detection
* No automated retraining
* No self-healing logic
* No production performance claims
* No accuracy optimization focus

These are deferred intentionally to avoid premature automation and incorrect system design.

---

## ğŸ“Š Dataset

**Give Me Some Credit (Kaggle)** â€” credit risk / default prediction dataset.

**Why it is used here:**

* Tabular, structured data
* Clear binary target
* Suitable for learning pipeline discipline

**Known limitations (acknowledged):**

* Static snapshot (no event-level timestamps)
* No natural delayed labels
* Limited realism for long-term drift analysis

This dataset is used **only for early phases** to build infrastructure.
Later phases will switch to temporally realistic datasets.

---

## ğŸ§± Project Structure

```
self-healing-mlops/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py              # Data loading logic
â”‚   â”œâ”€â”€ preprocessing.py     # Frozen preprocessing pipeline
â”‚   â”œâ”€â”€ train.py             # Model training + artifact creation
â”‚   â”œâ”€â”€ predict.py           # Shared inference logic
â”‚   â””â”€â”€ api.py               # FastAPI prediction service
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

> Note:
>
> * Raw data, trained artifacts, logs, and virtual environments are intentionally excluded from version control.

---

## âš™ï¸ Setup

### 1. Create virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ Train the Model

```bash
python src/train.py
```

This step:

* Loads data
* Applies frozen preprocessing
* Trains the model
* Saves artifacts (model, preprocessing, schema, metadata)

---

## ğŸš€ Run the API

```bash
uvicorn src.api:app --reload
```

### Endpoints

* Health check:

  ```
  GET /health
  ```
* Prediction:

  ```
  POST /predict
  ```

Interactive API docs:

```
http://localhost:8000/docs
```

---

## ğŸ”® Example Prediction Request

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "RevolvingUtilizationOfUnsecuredLines": 0.7,
    "age": 45,
    "NumberOfTime30-59DaysPastDueNotWorse": 1,
    "DebtRatio": 0.5,
    "MonthlyIncome": 6000,
    "NumberOfOpenCreditLinesAndLoans": 8,
    "NumberOfTimes90DaysLate": 0,
    "NumberRealEstateLoansOrLines": 1,
    "NumberOfTime60-89DaysPastDueNotWorse": 0,
    "NumberOfDependents": 2
  }'
```

---

## ğŸ§  Design Principles

This project prioritizes:

* **Correctness over cleverness**
* **Observability before automation**
* **Diagnosis before action**
* **Explicit constraints over hidden assumptions**

Retraining, drift detection, and â€œself-healingâ€ behavior are meaningless without a reliable foundation.

---

## ğŸ›£ï¸ Roadmap

* **Phase 1 (current)**
  Prediction service with reproducible artifacts and observability

* **Phase 2**
  Structured logging and monitoring-ready data collection

* **Phase 3**
  Drift detection and diagnosis (data drift vs concept drift)

* **Phase 4**
  Controlled retraining decisions (no naÃ¯ve auto-retrain)

* **Phase 5**
  Dataset evolution and validation on temporally realistic data

---

## ğŸ“Œ Status

**Phase 1: Complete**

This repository represents a **foundation**, not a finished system.

Subsequent phases will build incrementally on top of this base without breaking backward compatibility or system guarantees.

---
